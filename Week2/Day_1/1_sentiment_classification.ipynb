{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "536ac465",
   "metadata": {},
   "source": [
    "\n",
    "Open this on Google Colab: https://colab.research.google.com/drive/1zgMUH2DQCquWvLgJc2NBup0dDSnofvN0?usp=sharing  \n",
    " \n",
    "Model on HuggingFace: https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english \n",
    "\n",
    "## Libraries Explained\n",
    "\n",
    "- **dotenv**: Loads environment variables from a `.env` file into the application's environment, helping manage configuration separately from code.\n",
    "\n",
    "- **huggingface_hub**: \n",
    "  - **HfApi**: Provides programmatic access to the Hugging Face model hub for uploading, downloading, and managing models.\n",
    "  - **hf_hub_download**: Simplifies downloading model files from the Hugging Face hub to your local environment.\n",
    "\n",
    "- **transformers**: Offers pre-trained models for natural language processing tasks. The `pipeline` function specifically provides an easy-to-use interface for common NLP tasks like text generation, sentiment analysis, and question answering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3de16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, json, datetime\n",
    "from datetime import datetime\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7002eb",
   "metadata": {},
   "source": [
    "\n",
    "# Loading Environment Variables for Hugging Face\n",
    "\n",
    "\n",
    "This code snippet performs two essential operations:\n",
    "\n",
    "1. `load_dotenv()` - Loads environment variables from a `.env` file into the application's environment. This is a common pattern for securely storing configuration and sensitive information outside of the source code.\n",
    "\n",
    "2. `hf_key = os.getenv(\"HF_TOKEN\")` - Retrieves the Hugging Face API token from the environment variables and assigns it to the variable `hf_key`. This token is required for authenticated access to the Hugging Face Hub services, including downloading private models or models with gated access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18ba31ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_dotenv()\n",
    "hf_key=\"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff45713",
   "metadata": {},
   "source": [
    "\n",
    "# Hugging Face Model Reference\n",
    "\n",
    "[distilbert/distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english)\n",
    "\n",
    "This code defines a reference to a specific pre-trained model from the Hugging Face Model Hub. The model referenced is:\n",
    "\n",
    "- **Model**: `distilbert-base-uncased-finetuned-sst-2-english`\n",
    "- **Creator/Organization**: `distilbert`\n",
    "- **Description**: This is a DistilBERT model that has been fine-tuned on the Stanford Sentiment Treebank v2 (SST-2) dataset for sentiment analysis tasks. It can classify text as either positive or negative sentiment.\n",
    "- **Architecture**: DistilBERT (a distilled version of BERT that is smaller, faster, and requires fewer resources while maintaining good performance)\n",
    "- **Use Case**: Sentiment analysis and classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c361954",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_reference='distilbert/distilbert-base-uncased-finetuned-sst-2-english'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57032d97",
   "metadata": {},
   "source": [
    "\n",
    "# Using Hugging Face Inference API\n",
    "\n",
    "\n",
    "This code demonstrates how to use the Hugging Face Inference API for text classification:\n",
    "\n",
    "1. **Import**: First, the `InferenceClient` class is imported from the `huggingface_hub` package.\n",
    "\n",
    "2. **Client Initialization**: An `InferenceClient` object is created with:\n",
    "   - `provider=\"hf-inference\"` - Specifies using Hugging Face's hosted inference API\n",
    "   - `api_key=hf_key` - Uses the previously loaded API token for authentication\n",
    "\n",
    "3. **Text Classification**: The client performs sentiment analysis on the text \"I like you. I love you\" using the DistilBERT model defined earlier in `hf_reference`.\n",
    "\n",
    "4. **Result**: The final line will display the classification results, which typically include the predicted labels (positive/negative) and their associated confidence scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9326b830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextClassificationOutputElement(label='POSITIVE', score=0.9998738765716553),\n",
       " TextClassificationOutputElement(label='NEGATIVE', score=0.00012611244164872915)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "client = InferenceClient(provider=\"hf-inference\",api_key=hf_key,)\n",
    "\n",
    "result = client.text_classification(text=\"I like you. I love you\",model=hf_reference)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b4673a",
   "metadata": {},
   "source": [
    "\n",
    "# Downloading Specific Model Files from Hugging Face Hub\n",
    "\n",
    "\n",
    "This code snippet demonstrates how to selectively download specific files from a Hugging Face model repository:\n",
    "\n",
    "1. **File Definition**: First, a list of commonly required files for transformer models is defined, with comments explaining each file's purpose:\n",
    "   - Vocabulary files for tokenization\n",
    "   - Configuration files for model architecture\n",
    "   - Tokenizer files for text preprocessing\n",
    "   - Model weights in different formats (PyTorch and SafeTensors)\n",
    "\n",
    "2. **Selective Download**: The code iterates through each file in the list and:\n",
    "   - Attempts to download it using `hf_hub_download()`\n",
    "   - Specifies the model repository via `repo_id=hf_reference`\n",
    "   - Saves files to a local directory structure based on the model name\n",
    "   - Prints the local path where each file is saved\n",
    "\n",
    "3. **Error Handling**: The try-except block catches and reports any download failures, allowing the process to continue even if certain files aren't available for the specific model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c78b4f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to download: vocab.txt\n",
      "Saved to: models\\distilbert-base-uncased-finetuned-sst-2-english\\vocab.txt\n",
      "\n",
      "Attempting to download: vocab.json\n",
      "Could not download vocab.json: 404 Client Error. (Request ID: Root=1-6869498f-19e515e55877b41434a9d143;c5b4f991-d5bd-428e-b30a-82114801a025)\n",
      "\n",
      "Entry Not Found for url: https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.json.\n",
      "\n",
      "Attempting to download: config.json\n",
      "Saved to: models\\distilbert-base-uncased-finetuned-sst-2-english\\config.json\n",
      "\n",
      "Attempting to download: tokenizer.json\n",
      "Could not download tokenizer.json: 404 Client Error. (Request ID: Root=1-68694990-574f4bcf4eda0d8b527dbe77;5573a6dc-ffa5-41d2-a784-ee04a6966d25)\n",
      "\n",
      "Entry Not Found for url: https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json.\n",
      "\n",
      "Attempting to download: tokenizer_config.json\n",
      "Saved to: models\\distilbert-base-uncased-finetuned-sst-2-english\\tokenizer_config.json\n",
      "\n",
      "Attempting to download: merges.txt\n",
      "Could not download merges.txt: 404 Client Error. (Request ID: Root=1-68694991-756222da76ed074e1f6c3b48;53c0c678-be4f-4e97-a7a7-53d51f63211b)\n",
      "\n",
      "Entry Not Found for url: https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/merges.txt.\n",
      "\n",
      "Attempting to download: pytorch_model.bin\n",
      "Could not download pytorch_model.bin: [Errno 2] No such file or directory: 'models\\\\distilbert-base-uncased-finetuned-sst-2-english\\\\.cache\\\\huggingface\\\\download\\\\Q1p2l2BzM1m6P5jKvr8WTq1TUio=.60554cbd7781b09d87f1ececbea8c064b94e49a7f03fd88e8775bfe6cc3d9f88.incomplete'\n",
      "\n",
      "Attempting to download: model.safetensors\n",
      "Could not download model.safetensors: [Errno 2] No such file or directory: 'models\\\\distilbert-base-uncased-finetuned-sst-2-english\\\\.cache\\\\huggingface\\\\download\\\\xGOKKLRSlIhH692hSVvI1-gpoa8=.7c3919835e442510166d267fe7cbe847e0c51cd26d9ba07b89a57b952b49b8aa.incomplete'\n"
     ]
    }
   ],
   "source": [
    "# List of required files\n",
    "required_files = [\n",
    "    \"vocab.txt\",          # Vocabulary file (if applicable)\n",
    "    \"vocab.json\",          # Vocabulary file (if applicable)       \n",
    "    \"config.json\",        # Model configuration\n",
    "    \"tokenizer.json\",     # Tokenizer configuration (if applicable)\n",
    "    \"tokenizer_config.json\",     # Tokenizer configuration (if applicable)\n",
    "    \"merges.txt\",         # BPE merge rules file (if applicable)\n",
    "    \"pytorch_model.bin\",  # Model weights\n",
    "    \"model.safetensors\",  # Alternative model weights format\n",
    "]\n",
    "\n",
    "\n",
    "# Download only the required files\n",
    "for file_name in required_files:\n",
    "    try:\n",
    "        print()\n",
    "        print(f\"Attempting to download: {file_name}\")\n",
    "        local_path = hf_hub_download(repo_id=hf_reference, filename=file_name, local_dir=f\"models/{hf_reference.split('/')[1]}\")\n",
    "        print(f\"Saved to: {local_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not download {file_name}: {e}\")\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f50228",
   "metadata": {},
   "source": [
    "\n",
    "# Creating Sentiment Analysis Pipelines\n",
    "\n",
    "\n",
    "This code initializes two sentiment analysis pipelines using Hugging Face's `transformers` library:\n",
    "\n",
    "1. **Cached Model Pipeline**: \n",
    "   - `hf_model_cache` uses the model identifier directly (`hf_reference`)\n",
    "   - When this pipeline runs, it will first check the default Hugging Face cache directory on your system\n",
    "   - If not found in cache, it automatically downloads the model from Hugging Face Hub\n",
    "\n",
    "2. **Local Model Pipeline**:\n",
    "   - `hf_model_local` uses the previously downloaded model files\n",
    "   - Points to the local directory where model files were saved earlier\n",
    "   - Loads the model from the local files rather than downloading or using cache\n",
    "   - Path is constructed by extracting just the model name from the reference\n",
    "\n",
    "Both pipelines provide the same sentiment analysis functionality but differ in where they source the model files from, allowing flexibility between network-dependent and offline usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00ff4823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Raju Poosapati\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model models/distilbert-base-uncased-finetuned-sst-2-english with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'>). See the original errors:\n\nwhile loading with AutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 292, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 600, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4674, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1089, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<3 lines>...\n    )\nOSError: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory models/distilbert-base-uncased-finetuned-sst-2-english.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 310, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 600, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4674, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1089, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<3 lines>...\n    )\nOSError: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory models/distilbert-base-uncased-finetuned-sst-2-english.\n\nwhile loading with DistilBertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 292, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4674, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1089, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<3 lines>...\n    )\nOSError: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory models/distilbert-base-uncased-finetuned-sst-2-english.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 310, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4674, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1089, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<3 lines>...\n    )\nOSError: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory models/distilbert-base-uncased-finetuned-sst-2-english.\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m hf_model_cache = pipeline(\u001b[33m\"\u001b[39m\u001b[33msentiment-analysis\u001b[39m\u001b[33m\"\u001b[39m, model=hf_reference)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m hf_model_local = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentiment-analysis\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mhf_reference\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:1030\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1029\u001b[39m     model_classes = {\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m     framework, model = \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1040\u001b[39m model_config = model.config\n\u001b[32m   1041\u001b[39m hub_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = model.config._commit_hash\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:332\u001b[39m, in \u001b[36minfer_framework_load_model\u001b[39m\u001b[34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[39m\n\u001b[32m    330\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback.items():\n\u001b[32m    331\u001b[39m             error += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    333\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    334\u001b[39m         )\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    337\u001b[39m     framework = infer_framework(model.\u001b[34m__class__\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Could not load model models/distilbert-base-uncased-finetuned-sst-2-english with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'>). See the original errors:\n\nwhile loading with AutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 292, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 600, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4674, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1089, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<3 lines>...\n    )\nOSError: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory models/distilbert-base-uncased-finetuned-sst-2-english.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 310, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 600, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4674, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1089, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<3 lines>...\n    )\nOSError: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory models/distilbert-base-uncased-finetuned-sst-2-english.\n\nwhile loading with DistilBertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 292, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4674, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1089, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<3 lines>...\n    )\nOSError: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory models/distilbert-base-uncased-finetuned-sst-2-english.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 310, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4674, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Raju Poosapati\\Python_Venvs\\Test_Venv\\Test_Venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1089, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<3 lines>...\n    )\nOSError: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory models/distilbert-base-uncased-finetuned-sst-2-english.\n\n\n"
     ]
    }
   ],
   "source": [
    "hf_model_cache = pipeline(\"sentiment-analysis\", model=hf_reference)\n",
    "hf_model_local = pipeline(\"sentiment-analysis\", model=f\"models/{hf_reference.split('/')[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fce28f",
   "metadata": {},
   "source": [
    "\n",
    "# Testing the Sentiment Analysis Model\n",
    "\n",
    "\n",
    "This code demonstrates how to use the local sentiment analysis pipeline:\n",
    "\n",
    "1. **Input Text**: Defines a medical text about high blood sugar and blood pressure readings\n",
    "\n",
    "2. **Model Inference**: Passes the text to the previously initialized local sentiment analysis model (`hf_model_local`)\n",
    "\n",
    "3. **Output Display**: Prints the classification results, which typically include:\n",
    "   - The predicted sentiment label (POSITIVE or NEGATIVE)\n",
    "   - A confidence score indicating the model's certainty\n",
    "   \n",
    "Note that this medical statement is factual rather than emotionally charged, so the model's sentiment prediction may not be particularly meaningful in this context. Sentiment analysis models work best with text that expresses opinions or emotional reactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dbf2fd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_model_local' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33mThe Medical reports reveal Blood sugar and Blood pressure are high\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mhf_model_local\u001b[49m(text))\n",
      "\u001b[31mNameError\u001b[39m: name 'hf_model_local' is not defined"
     ]
    }
   ],
   "source": [
    "text = \"The Medical reports reveal Blood sugar and Blood pressure are high\"\n",
    "print(hf_model_local(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb652c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The students from this school score very high marks\"\n",
    "print(hf_model_local(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The Medical reports reveal Blood sugar and Blood pressure are high\"\n",
    "print(hf_model_cache(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e47568",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The students from this school score very high marks\"\n",
    "print(hf_model_cache(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827796a5",
   "metadata": {},
   "source": [
    "\n",
    "# Serialize and Save Model Information from Hugging Face Hub\n",
    "\n",
    "\n",
    "This code demonstrates how to retrieve, serialize, and save detailed model information from the Hugging Face Hub:\n",
    "\n",
    "1. **Serialization Function**: The `serialize_object()` function handles complex objects recursively:\n",
    "   - Converts datetime objects to ISO format strings\n",
    "   - Transforms objects with `__dict__` attributes into dictionaries\n",
    "   - Processes nested lists and dictionaries\n",
    "   - Preserves primitive data types\n",
    "\n",
    "2. **API Interaction**: Creates an instance of the Hugging Face API client\n",
    "\n",
    "3. **Model Information**: Fetches comprehensive metadata about the specified model using `api.model_info()`\n",
    "\n",
    "4. **File Operations**: \n",
    "   - Extracts the model name from the reference path\n",
    "   - Creates a JSON file named after the model\n",
    "   - Serializes the model information and writes it to the file\n",
    "\n",
    "This allows for local storage of model metadata for later reference or analysis, particularly useful for model governance, versioning, and documentation purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_object(obj):\n",
    "    \"\"\"\n",
    "    Helper function to serialize custom objects like EvalResult.\n",
    "    Converts objects with __dict__ attribute to dictionaries and handles datetime objects.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, datetime):\n",
    "        return obj.isoformat()  # Convert datetime to ISO 8601 string\n",
    "    elif hasattr(obj, \"__dict__\"):\n",
    "        return {key: serialize_object(value) for key, value in obj.__dict__.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [serialize_object(item) for item in obj]\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: serialize_object(value) for key, value in obj.items()}\n",
    "    else:\n",
    "        return obj  # Return the value as-is for primitive types\n",
    "\n",
    "api = HfApi()\n",
    "with open(f\"models/{hf_reference.split('/')[1]}.json\", \"w\") as json_file:\n",
    "    json_file.write(json.dumps(serialize_object(api.model_info(hf_reference))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Test_Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
